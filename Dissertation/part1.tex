\chapter{Обзор методов распознавания иероглифических текстов при расшифровке и поиске}\label{ch:ch1}

В данной главе рассматривается широкий круг методов распознавания иероглифических текстов, которые на протяжении нескольких десятилетий остаются одной из наиболее сложных и актуальных задач в области компьютерного зрения, анализа изображений и обработки документов.

Для анализа печатных изображений документов были разработаны передовые методы, которые позволяют достигать высокого качества распознавания и уже успешно применяются в различных системах автоматизации рутинных процессов \cite{reisswig2019chargrid, smith2007overview, du2009pp, li2023trocr, xu2020layoutlm}. В то же время распознавание рукописных архивных текстов по-прежнему остаётся значительно менее изученной и более сложной задачей.

Исторически исследования в данной области развивались в двух взаимосвязанных, но концептуально различных направлениях. Первое направление ориентировано на \textit{задачу распознавания и декодирования иероглифов}, то есть на установление соответствия между изображением символа и его семантическим или кодовым представлением. В рамках этого подхода основной целью является получение последовательности символов в машиночитаемом виде, что позволяет использовать распознанный текст для дальнейшей лингвистической обработки, индексирования, перевода и анализа содержания. Второе направление связано с \textit{задачами поиска}, сопоставления и группировки иероглифических форм, где ключевым является не столько точное восстановление символа, сколько выявление графического сходства между изображениями, независимо от их интерпретации на уровне языка.

В отличие от алфавитных систем письма, особая сложность распознавания иероглифических текстов, таких как китайская, обусловлена рядом факторов. Во-первых, количество различных иероглифов может достигать десятков тысяч, при этом многие из них встречаются крайне редко, что приводит к проблеме дефицита обучающих данных. Во-вторых, иероглифы характеризуются сложной внутренней структурой, включающей радикалы, штрихи и их пространственные отношения, которые могут изменяться в зависимости от стиля письма, эпохи, носителя или технических условий оцифровки. В-третьих, значительную роль играют деградации изображения \cite{shi2023m5hisdoc}, такие как шум, разрывы штрихов, искажения, а также особенности исторических документов, включая нестандартизированные формы и архаические варианты написания.

В рамках данной главы проводится систематический обзор существующих методов, применяемых для решения указанных задач. Схема классификации рассматриваемых методов приведена на рисунке \cref{fig:sec1_literature_review}. Рассматриваются как традиционные подходы, основанные на ручном проектировании признаков, структурном анализе и сопоставлении графов или скелетных представлений, так и современные методы машинного обучения и глубоких нейронных сетей. Особое внимание уделяется принципиальным различиям между методами, ориентированными на распознавание символов как конечных классов, и подходами, направленными на извлечение инвариантных графических представлений, пригодных для задач поиска и сопоставления. Кроме того, в обзоре анализируются достоинства и ограничения различных классов методов с точки зрения их применимости к различным сценариям, включая распознавание печатных и рукописных текстов, а также задачи с ограниченным числом размеченных данных, такие как однократное (one-shot) и малократное (few-shot) обучение.

\begin{figure}[ht]
    \centerfloat{
        \includegraphics[width=1.0\linewidth]{sec1_literature_review.jpg}
    }
    \caption[Классификация методов распознавания текстов]{Классификация методов распознавания текстов}\label{fig:sec1_literature_review}
\end{figure}

Таким образом, данная глава формирует теоретическую и методологическую основу для последующего анализа и разработки методов распознавания иероглифических текстов, а также позволяет наглядно продемонстрировать эволюцию подходов от классических алгоритмов к современным нейросетевым решениям в контексте задач расшифровки и поиска.

\section{Методы, основанные на принципе расшифровки}\label{sec:ch1/sec1}
Методы, относящиеся к принципу расшифровки, являются на сегодняшний день основным и наиболее широко распространённым направлением в области распознавания текстов, включая распознавание иероглифических письменностей. Данный класс подходов ориентирован на непосредственное восстановление символической последовательности по входному изображению, то есть на установление однозначного соответствия между графическим образом иероглифа и его кодовым или лексическим представлением. Именно такие методы лежат в основе большинства современных систем оптического распознавания текста (OCR), применяемых для обработки печатных и рукописных документов, архивных материалов и цифровых библиотек.

В рамках данной группы методов условно можно выделить три основных класса. Первый класс составляют традиционные методы, основанные на признаковых дескрипторах, в которых ключевую роль играет ручное извлечение структурных, геометрических и топологических характеристик иероглифов. Второй класс включает статистические методы расшифровки, использующие вероятностные модели, методы классификации и последовательностного декодирования. Наконец, третий и наиболее активно развивающийся класс представлен нейросетевыми методами, основанными на глубинном обучении.

\subsection{Традиционные методы признаковых дискрипторов}

Традиционные методы распознавания символов рассматривают иероглиф как чисто графическую форму, представленную в виде двумерного изображения. Основная идея таких подходов заключается в явном извлечении заранее разработанных признаков, которые однозначно описывают визуальную структуру символа и позволяют отличать его от других классов. Далее на основе этих признаков выполняется сравнение с эталонными шаблонами или классификация посредством классических алгоритмов распознавания образов, таких как ближайшие соседи или линейные классификаторы. Эта схема является фундаментальной для классических систем оптического распознавания символов и широко представлена в литературе как базовая стратегия обработки визуальных символов на изображении. \cite{verma2012survey}

Важнейшим элементом этих методов является выбор типа признаков, адекватно описывающих форму символа. Выбор и качество дескрипторов напрямую определяют эффективность последующей классификации. Рассматриваются три основные типа признаков, часто встречающихся в традиционных методах: \textit{контурные, структурные и скелетные} признаки.

Пусть бинарное изображение символа задаётся как
\[
    I:\Omega \subset \mathbb{Z}^2\to \{0,1\},
\]
где $I(x,y)=1$ соответствует пикселям символа, а $I(x,y)=0$ — фону. \textbf{Контурные признаки} основаны на анализе границы символа. Контур $\mathcal{C}$ определяется как множество граничных пикселей:
\[
    \mathcal{C} = \{(x,y)\in\Omega | I(x,y) = 1 \land \exists (x', y')\in\mathcal{N}(x,y):I(x', y')=0\},
\]
где $\mathcal{N}(x,y)$ — окрестность пикселя. Один из классических способов представления контура — \textit{цепной код Фримена}, который задаёт контур в виде последовательности направлений:
\[
    d = (d_1, d_2, \cdots,d_N), d_i \in\{0,\cdots,7\},
\]
где каждое направление соответствует смещению между соседними граничными пикселями. Альтернативно контур может быть представлен параметрически:
\[
    \mathcal{C}(s) = (x(s), y(s)), s\in[0,L],
\]
где $L$ — длина контура. На основе параметрического представления вычисляются производные признаки, такие как кривизна:
\[
    k(s) = \frac{x'(s)y''(s) - y'(s)x''(s)}{(x'(s)^2 + y'(s)^2)^{3/2}},
\]
или профили расстояний до центра масс:
\[
    r(s) = \sqrt{(x(s) - \bar{x})^2 + (y(s) - \bar{y})^2 }.
\]
Контурные признаки хорошо отражают форму границы символа, однако чувствительны к шуму, разрывам контура и локальным деформациям.

\textbf{Структурные признаки} стремятся описать символ как совокупность осмысленных геометрических примитивов и их взаимного расположения. В этом подходе изображение символа интерпретируется как структурный объект, состоящий из штрихов, узлов и точек пересечения.

Формально символ может быть представлен в виде ориентированного графа:
\[
    G=(V,E),
\]
где множество вершин $V$ соответствует ключевым точкам структуры (концы штрихов, точки ветвления, пересечения), а множество рёбер $E$ — штрихам между ними. Каждому ребру $e \in E$ может быть сопоставлен вектор атрибутов:
\[
    \phi(e) = (\ell(e), \theta(e), w(e)),
\]

где $\ell(e)$ — длина штриха, $\theta(e)$ — его ориентация, $w(e)$ — средняя толщина. Структурное описание может быть дополнено матрицей смежности:
\[
    A_{ij} =
    \begin{cases}
        1, & \text{если} (v_i, v_j)\in E, \\
        0, & \text{в противном случае}.
    \end{cases}
\]
что позволяет анализировать топологию символа. Подобные признаки особенно информативны для иероглифических систем письма, где семантически значимыми являются количество и конфигурация штрихов.

\textbf{Скелетные признаки} основаны на скелетизации изображения, целью которой является получение одномерного представления формы при сохранении её топологии. Скелет $\mathcal{S}$ бинарного изображения определяется как медиальная ось:
\[
    \mathcal{S} = \{p\in\Omega | \exists \text{ по меньшей мере две ближайшие точки контура к } p\},
\]
что эквивалентно множеству центров максимальных вписанных дисков. Cкелетизация может быть реализоваться с помощью морфологических операций истончения:
\[
    \mathcal{S} = \bigcap_{k=1}^{K}(I\ominus B_k),
\]
где $B_k$ — структурные элементы, а $\ominus$ обозначает морфологическую эрозию. Полученный скелет может быть представлен в виде графа:
\[
    G_s=(V_s,E_s),
\]
где вершины соответствуют конечным точкам и точкам ветвления, а рёбра — сегментам скелета. Основными скелетными и топологическими признаками являются \(deg(v), |V_s|, |E_s|\), число циклов, что обеспечивает инвариантность к локальным деформациям толщины штрихов. Скелетные признаки обладают высокой устойчивостью к изменениям масштаба и толщины линий, однако чувствительны к ошибкам бинаризации и шуму, способным существенно изменить топологию скелета.

На основе таких признаков были разработаны классические правил-ориентированные системы, в которых каждому символу соответствует один или несколько эталонных шаблонов, а распознавание осуществляется через минимизацию расстояния между признаками входного и эталонного образцов. Эти стратегии играют центральную роль в ранних OCR-системах и часто использовались до широкого распространения методов машинного обучения.

% Приемущества и недостатки
Одним из ключевых преимуществ традиционных дескрипторных методов является их интерпретируемость: каждый признак или правило ясно соотносится с конкретным элементом формы, что позволяет исследователю анализировать и понимать поведение алгоритма на каждом этапе. Такие методы также не требуют больших размеченных обучающих выборок, что делает их привлекательными для приложений с ограниченными данными, когда сбор большого корпуса для обучения оказывается сложным или невозможным.

Однако эти методы обладают рядом существенных ограничений. Во-первых, они очень чувствительны к шумам, искажениям изображения и вариативности почерка, поскольку ручные признаки фиксированы и не адаптируются к изменениям формы, что резко снижает устойчивость к деформированным или повреждённым образцам. Во-вторых, при попытке масштабирования на большие словари и сложные исторические формы классические подходы сталкиваются с резким ростом сложности шаблонов и правил, что сказывается на вычислительной эффективности и практической применимости в задачах обработки древних рукописей. Несмотря на интерпретируемость, данные методы оказываются малоэффективными при работе с большими и открытыми словарями иероглифов, характерными для исторических рукописей.

\subsection{Статистические методы расшифровки иероглифов}

Статистические методы распознавания символов возникли как попытка преодолеть ограничения традиционных правил-ориентированных алгоритмов путём перехода от жёстких эвристик к вероятностным моделям и статистическому описанию признаков. В отличие от чисто правил-ориентированных подходов, статистические методы формируют модель, которая аппроксимирует распределение признаков или их зависимости, что позволяет формализовать неопределённость и вариативность в данных, характерную для реальных изображений рукописных или печатных символов. Такие методы лежат в основе классической теории статистического распознавания образов и машинного обучения, и широко применялись в ранних системах распознавания текстов для обработки изображений текста.

% Статистические признаки
Статистические признаки являются альтернативными и более применяемыми в отличие от правил-ориентированных признаков, которые извлекаются главным образом путем анализа структуры композиции, штрихов и радикалов символов. К числу наиболее распространённых и эффективных статистических признаков, применяемых в задачах распознавания иероглифических символов, относятся гистограммы ориентированных градиентов (HOG), признаки на основе фильтров Габора, признаки независимого компонентного анализа (ICA), а также обобщённые градиентные признаки.

\begin{figure}[ht]
    \centerfloat{
        \includegraphics[width=1.0\linewidth]{sec1_statistical_methods.jpg}
    }
    \caption[Общая схема системы распознавания текстов с использованием статистических методов]{Общая схема системы распознавания текстов с использованием статистических методов}\label{fig:sec1_statistical_methods}
\end{figure}

В работе \cite{shen2023challenges} представлена обобщённая схема функционирования классической системы распознавания текстов (рисунок \cref{fig:sec1_statistical_methods}). Она включает этапы предварительной обработки данных, извлечения статистических признаков и последующей классификации с использованием методов машинного обучения. Ключевыми этапами данной процедуры являются извлечение признаков и классификация, на которых применяются подходы, основанные на принципах, отличных от традиционных методов.

Пусть исходное изображение символа задаётся функцией яркости
\[
    I: \Omega \subset \mathbb{Z}^2 \rightarrow \mathbb{R}.
\]

\paragraph{Признаки HOG (Histogram of Oriented Gradients)}\cite{meygret1992robust}
Признаки HOG основаны на статистическом анализе распределения направлений градиента яркости в локальных областях изображения. Для каждого пикселя вычисляется градиент:
\[
    \nabla I(x,y) =
    \left(
    \frac{\partial I}{\partial x},
    \frac{\partial I}{\partial y}
    \right)
\]
его модуль
\[
    m(x,y) =
    \sqrt{
        \left(\frac{\partial I}{\partial x}\right)^2
        +
        \left(\frac{\partial I}{\partial y}\right)^2
    },
\]
и ориентация
\[
    \theta(x,y) =
    \arctan\left(
    \frac{\partial I / \partial y}
    {\partial I / \partial x}
    \right).
\]
Изображение разбивается на набор ячеек ${\mathcal{C}_k}$ фиксированного размера. Для каждой ячейки строится гистограмма ориентаций:
\[
    h_k(b) =
    \sum_{(x,y) \in \mathcal{C}_k}
    w_b\!\left(\theta(x,y)\right)
    \, m(x,y),
\]
где $b$ — номер ориентационного бина, а $w_b(\cdot)$ — функция взвешивания. Для повышения устойчивости к изменениям освещения выполняется нормализация на уровне блоков:
\[
    \hat{h}_k =
    \frac{h_k}
    {\sqrt{\|h_k\|_2^2 + \varepsilon}}.
\]
HOG-признаки эффективно кодируют локально направленные штрихи и переходы яркости, что делает их особенно подходящими для распознавания печатных и рукописных иероглифов.

\paragraph{Признаки на основе фильтров Габора (Gabor features)}\cite{hamamoto1995recognition}
Признаки Габора формируются путём свёртки изображения с набором полосовых фильтров, параметризованных ориентацией и пространственной частотой. Двумерный фильтр Габора задаётся как:
\[
    g_{\lambda,\theta,\psi,\sigma,\gamma}(x,y)
    =
    \exp\!\left(
    -\frac{x'^2 + \gamma^2 y'^2}{2\sigma^2}
    \right)
    \cos\!\left(
    2\pi \frac{x'}{\lambda} + \psi
    \right),
\]
где
\[
    \begin{aligned}
        x' & = x \cos\theta + y \sin\theta, \\
        y' & = -x \sin\theta + y \cos\theta
    \end{aligned}.
\]
Выход фильтра определяется как:
\[
    R_{\lambda,\theta}(x,y)
    =
    (I * g_{\lambda,\theta})(x,y),
\]
а признаки формируются на основе статистик амплитуды:
\[
    f_{\lambda,\theta}
    =
    \frac{1}{|\Omega|}
    \sum_{(x,y)\in\Omega}
    \left|
    R_{\lambda,\theta}(x,y)
    \right|.
\]
Использование банка фильтров с различными $\lambda$ и $\theta$ позволяет кодировать локальные частотно-ориентационные характеристики изображения, обеспечивая устойчивость к вариациям масштаба, наклона и толщины штрихов.

\paragraph{Признаки, основанные на независимом компонентном анализе (Independent Component Analysis, ICA)}\cite{chang1994word}
Признаки ICA направлены на статистическое разложение изображения или его векторного представления на набор максимально независимых компонент. Пусть изображение преобразовано в вектор наблюдений \(x\in\mathbb{R}^n\). Модель ICA предполагает линейную смесь скрытых источников:
\[
    x = As
\],
где $\mathbf{s} = (s_1, \ldots, s_m)^\top$ — вектор независимых компонент, а $A$ — матрица смешивания. Задача ICA заключается в нахождении матрицы разделения $W$:
\[
    s = Wx,
\]
максимизирующей статистическую независимость компонент, как правило, путём оптимизации негaуссовости:
\[
    \max_W
    \sum_i
    \left|
    \mathbb{E}[G(s_i)]
    -
    \mathbb{E}[G(v)]
    \right|,
\]
где $v$ — гауссовская случайная величина, а $G(\cdot)$ — нелинейная функция. В контексте распознавания текстов полученные независимые компоненты могут интерпретироваться как базисные штриховые или локальные структурные элементы, обеспечивая выразительное описание сложных иероглифических форм.

\paragraph{Градиентные признаки}\cite{chang1999analysis}
Градиентные признаки представляют собой обобщённый класс статистических дескрипторов, основанных на анализе поля градиентов изображения. В простейшем случае формируется вектор признаков:
\[
    \mathbf{f} =
    \left(
    \mathbb{E}[m],\;
    \mathbb{E}[\theta],\;
    \mathrm{Var}(m),\;
    \mathrm{Var}(\theta)
    \right),
\]
где математические ожидания и дисперсии вычисляются по области символа. Более сложные варианты включают агрегирование градиентных характеристик по регионам изображения:
\[
    f_r =
    \sum_{(x,y)\in \Omega_r}
    \phi\!\left(
    m(x,y), \theta(x,y)
    \right),
\]
где $\Omega_r$ — локальная область, а $\phi(\cdot)$ — функция кодирования. Такие признаки позволяют эффективно описывать геометрию штрихов и контуры символа при сравнительно низкой вычислительной сложности.

% Классификаторы
Избавление от правил-ориентированных подходов тоже отражается при выборе классификаторов. Простые методы, такие как k-ближайших соседей (k-Nearest Neighbors, kNN) \cite{eko2021bonferroni}, представляют собой непараметрические классификаторы, которые присваивают метку класса на основе ближайших примеров в признаковом пространстве без построения явной модели распределения. Несмотря на их простоту, kNN и его вариации использовались в задачах распознавания текстов как базовые методы, особенно при сравнении с более сложными подходами.

Также применяются методы опорных векторов (Support Vector Machines, SVM) \cite{wang2008novel}, которые оптимизируют границу между классами в высокоразмерном пространстве признаков и могут обеспечивать высокую общую точность при наличии достаточно репрезентативных тренировочных данных.

Одним из значимых статистических классификаторов, широко применяемых в задачах оптического распознавания текстов, является модифицированная квадратичная дискриминантная функция (Modified Quadratic Discriminant Function, MQDF) \cite{kimura1987modified, wei2018compact}, специально адаптированная для условий большого числа классов, характерного для китайских иероглифических систем письма. Пусть каждый образ символа представлен в виде вектора признаков $x\in \mathbb{R}^d$, а для каждого класса $\omega_k$ заданы оценки математического ожидания $\boldsymbol{\mu}_k$ и ковариационной матрицы $\Sigma_k$, характеризующей внутриклассовую вариативность признаков. В рамках предположения о нормальном распределении признаков классическая квадратичная дискриминантная функция имеет вид:

\[
    g_k^{\mathrm{QDF}}(\mathbf{x}) =
    (\mathbf{x}-\boldsymbol{\mu}_k)^\top
    \Sigma_k^{-1}
    (\mathbf{x}-\boldsymbol{\mu}_k)
    +
    \log|\Sigma_k|,
\]
Однако при высокой размерности пространства признаков и ограниченном числе обучающих выборок надёжная оценка полной ковариационной матрицы становится затруднительной, что особенно критично для задач распознавания тысяч классов иероглифов. MQDF предлагает эффективную модификацию данного подхода, основанную на спектральном разложении ковариационной матрицы:
\[
    \Sigma_k = U_k \Lambda_k U_k^\top,
\]
где $\Lambda_k = \mathrm{diag}(\lambda_{k,1}, \ldots, \lambda_{k,d})$ — упорядоченные по убыванию собственные значения, а $U_k = (\mathbf{u}_{k,1}, \ldots, \mathbf{u}_{k,d})$ — соответствующие собственные векторы. В MQDF сохраняются только $r \ll d$ наиболее значимых компонент, отражающих основную коррелированную структуру признаков, тогда как вклад оставшихся компонент аппроксимируется скалярным параметром регуляризации $\delta_k$. При этом аппроксимированная ковариационная модель принимает вид:
\[
    \tilde{\Sigma}_k =
    \sum_{i=1}^{r}
    \lambda_{k,i}
    \mathbf{u}_{k,i}\mathbf{u}_{k,i}^\top
    +
    \delta_k
    \sum_{i=r+1}^{d}
    \mathbf{u}_{k,i}\mathbf{u}_{k,i}^\top,
\]
что существенно снижает число оцениваемых параметров и повышает устойчивость классификатора. Соответствующая дискриминантная функция MQDF может быть записана как:
\[
    \begin{aligned}
        g_k^{\mathrm{MQDF}}(\mathbf{x}) & =
        \sum_{i=1}^{r}
        \frac{
            \left(
            \mathbf{u}_{k,i}^\top
            (\mathbf{x}-\boldsymbol{\mu}_k)
            \right)^2
        }{\lambda_{k,i}}
        +
        \frac{
            \left\|
            (\mathbf{x}-\boldsymbol{\mu}_k)
            -
            \sum_{i=1}^{r}
            \mathbf{u}_{k,i}\mathbf{u}_{k,i}^\top
            (\mathbf{x}-\boldsymbol{\mu}_k)
            \right\|^2
        }{\delta_k}
        \\
                                        & \quad+
        \sum_{i=1}^{r}\log\lambda_{k,i}
        +
        (d-r)\log\delta_k.
    \end{aligned}
\]
Решение о принадлежности образа принимается по правилу минимизации:
\[
    \hat{k} =
    \arg\min_k
    g_k^{\mathrm{MQDF}}(\mathbf{x}).
\]
Благодаря явному учёту корреляций внутри признакового вектора и использованию низкоранговой аппроксимации ковариационной структуры, MQDF-классификаторы демонстрируют высокую точность при распознавании сложных иероглифических форм. Практика применения показала, что данный подход особенно эффективен в задачах оффлайн-распознавания китайских иероглифов и сохраняет стабильность работы даже при ограниченных объёмах обучающих данных и большом числе классов.

% Приемущества и недостатки
Преимущества статистических методов очевидны по сравнению с чисто правил-ориентированными алгоритмами: более высокая устойчивость к вариациям формы благодаря статистическому моделированию, а также \textit{формализация неопределённости}, присущей реальным образам, через вероятностные оценки. Это позволяет уменьшить влияние отдельных атипичных примеров и улучшает общую стабильность распознавания.

Вместе с тем существуют ключевые ограничения. Во-первых, статистические методы зависимы от качества признаков — если исходные ручные дескрипторы плохо характеризуют форму символа, ни одна статистическая модель не сможет компенсировать этот недостаток. Во-вторых, для корректной работы большинства моделей требуется представительная обучающая выборка, охватывающая все значимые вариации символов, без неё параметры моделей плохо оцениваются. И наконец, при работе с редкими классами или открытыми словарями качество распознавания резко падает, так как модели не видели этих форм в обучении и не имеют механизмов для адекватной генерализации.

\subsection{Нейросетевые методы расшифровки иероглифов}
С появлением глубокого обучения нейросетевые методы стали ведущим подходом в задачах оптического распознавания символов благодаря своей способности автоматически извлекать высокоуровневые признаки напрямую из данных без необходимости ручной инженерии дескрипторов. Эти методы обучаются в end-to-end режиме с градиентыми методами оптимизации, где входное изображение проходит через серию слоёв нейронной сети, а выходом является предсказание класса символа или последовательности символов. Такая схема позволила преодолеть многие ограничения традиционных методов и достигла впечатляющей точности на стандартизированных наборах данных, особенно для латинского и китайского текста. \cite{xu2022sophisticated, yang2017improving, zhong2016handwritten, zhuang2021handwritten, coquenet2023faster}.

% CNN / RNN / Transformer
Одним из основополагающих архитектурных решений в области современного оптического распознавания символов являются свёрточные нейронные сети (Convolutional Neural Networks, CNN), которые особенно хорошо подходят для распознавания отдельных иероглифов. Общая схема свёрточных сетей для распознавания иероглифов представлена на рисунке \cref{fig:sec1_cnn}. В отличие от традиционных подходов, основанных на заранее сконструированных признаках, CNN реализуют принцип автоматического обучения иерархических представлений непосредственно из изображений.

\begin{figure}[ht]
    \centerfloat{
        \includegraphics[width=1.0\linewidth]{sec1_cnn.png}
    }
    \caption[Схема свёрточных сетей для распознавания иероглифов]{Схема свёрточных сетей для распознавания иероглифов. В сети обычно включаются сверточные слои (convolutional layer), подвыборочные слои (pooling layer), и полносвязный слой (fully-connected layer).}\label{fig:sec1_cnn}
\end{figure}

Пусть входное изображение иероглифа представлено в виде тензора \(\mathbf{X} \in \mathbb{R}^{H \times W \times C}\), где $H$ и $W$ — пространственные размеры изображения, а $C$ — число каналов. Основной операцией CNN является свёртка, при которой на каждом слое формируются карты признаков:
\[
    \mathbf{Z}^{(l)}_k =
    \mathbf{W}^{(l)}_k * \mathbf{X}^{(l-1)} + b^{(l)}_k,
\]
где $\mathbf{W}^{(l)}_k$ — свёрточное ядро $k$-го канала $l$-го слоя, $b^{(l)}_k$ — смещение, а символ $*$ обозначает операцию дискретной свёртки. Результат затем пропускается через нелинейную функцию активации:
\[
    \mathbf{X}^{(l)}_k =
    \sigma\!\left(
    \mathbf{Z}^{(l)}_k
    \right).
\]
Последовательное применение свёрточных и подвыборочных (pooling) слоёв:
\[
    \mathbf{X}^{(l)} =
    \mathcal{P}\!\left(
    \mathbf{X}^{(l-1)}
    \right),
\]
позволяет формировать многоуровневое представление изображения, в котором нижние слои кодируют простые локальные структуры (границы, направления штрихов), а более глубокие — сложные композиционные элементы формы иероглифа. Таким образом, CNN реализуют иерархию признаков, обладающих инвариантностью к сдвигам, масштабным изменениям и локальным деформациям. В классической работе \cite{lecun2002gradient} было показано, что обучение параметров сети путём минимизации эмпирической функции потерь
\[
    \mathcal{L} =
    \sum_{i=1}^{N}
    \ell\!\left(
    f(\mathbf{X}_i;\boldsymbol{\theta}),
    y_i
    \right),
\]
где $f(\cdot;\boldsymbol{\theta})$ — отображение, задаваемое CNN с параметрами $\boldsymbol{\theta}$, позволяет автоматически извлекать инвариантные образные признаки, существенно превосходящие по дискриминативной способности традиционные ручные дескрипторы, такие как HOG, при распознавании рукописных цифр и букв.

Данная идея естественным образом переносится на задачу распознавания китайских иероглифов. В этом случае CNN обучаются на больших размеченных выборках \(\{(\mathbf{X}_i, y_i)\}_{i=1}^{N}\), где число классов $K$ может достигать нескольких тысяч. За счёт совместного обучения признакового представления и классификатора, свёрточные нейронные сети демонстрируют высокую точность распознавания иероглифов сложной структуры и служат базовой архитектурой для большинства современных систем распознавания текстов.

Для задач, в которых требуется распознавание последовательностей символов в строках текста, широко применяются гибридные модели, объединяющие сверточные нейронные сети с последовательностными архитектурами, такими как рекуррентные нейронные сети (Recurrent Neural Networks, RNN), а также модели, основанные на механизмах внимания. Пусть входное изображение текстовой строки после обработки сверточной сетью представлено в виде последовательности признаковых векторов:
\[
    \mathbf{F} = (\mathbf{f}_1, \mathbf{f}_2,\cdots,\mathbf{f}_T), \mathbf{f}_t\in\mathbb{R}^d,
\]
где $T$ соответствует длине последовательности по горизонтальной оси изображения. Задача распознавания формулируется как отображение входной последовательности признаков в последовательность символов:
\[
    \mathbf{y} = (y_1, y_2, \cdots, y_L), y_l \in \mathcal{A},
\]
где $\mathcal{A}$ — алфавит символов. В RNN скрытое состояние $\mathbf{h}_t$ обновляется рекурсивно:
\[
    \mathbf{h}_t = \phi(\mathbf{W}_x\mathbf{f}_t + \mathbf{W}_h\mathbf{h}_{t-1} + \mathbf{b}),
\]
где $\phi(\cdot)$ — нелинейная функция, а параметры $\mathbf{W}_x$, $\mathbf{W}_h$ и $\mathbf{b}$ обучаются по данным. Для повышения способности моделировать дальние зависимости обычно используются архитектуры LSTM \cite{greff2016lstm} или GRU \cite{chung2014empirical}. Выходные вероятности символов на каждом временном шаге задаются как:
\[
    p(y_t | \mathbf{F}) = \text{Softmax}(\mathbf{W}_o\mathbf{h}_t).
\]
В работе \cite{shi2016end} была предложена архитектура CNN–RNN с функцией потерь CTC (Connectionist Temporal Classification), позволяющая обучать модель без предварительной сегментации символов. Вероятность последовательности меток определяется как сумма по всем допустимым выравниваниям:
\[
    p(y|\mathbf{F}) = \sum_{\pi\in\mathcal{B}^{-1}(y)}\prod_{t=1}^{T}p(\pi_t|\mathbf{F}),
\]
где $\pi$ — путь выравнивания, а $\mathcal{B}$ — операция схлопывания повторяющихся меток. Данный подход стал одним из стандартов в современных системах распознавания текстовых строк.

Позднее получили развитие методы, основанные на механизме внимания, в которых выходная последовательность формируется путём явного моделирования зависимостей между элементами входа. В общем виде механизм внимания определяется как:
\[
    \text{Attention}(Q,K,V) = \text{Softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V
\]
где $Q$, $K$ и $V$ — матрицы запросов, ключей и значений соответственно, а $d_k$ - размерность ключей $K$. Трансформерные архитектуры \cite{vaswani2017attention} полностью отказываются от рекуррентных связей и используют многоуровневое самовнимание для кодирования последовательности признаков:
\[
    \mathbf{Z}^{(l)} = \text{MHSA}(\mathbf{Z}^{(l-1)})
\]
где $\mathrm{MHSA}$ обозначает многооголовое самовнимание. Позиционная информация вводится с помощью позиционных кодировок:
\[
    \mathbf{Z}_t^{(0)} = \mathbf{f}_t + \mathbf{p}_t
\]
Общая схема архитектуры трансформера показана на рисунке \cref{fig:sec1_transformer}. В контексте распознавания текстов трансформеры применяются для прямого декодирования текстовой последовательности из визуальных признаков, что позволяет эффективно моделировать долгосрочные зависимости между символами и словами. Современные архитектуры \cite{lin2021vibertgrid, fujitake2024dtrocr} демонстрируют высокую точность на сложных задачах распознавания текстов без явной предварительной разметки или сегментации, превосходя классические CNN–RNN модели.

\begin{figure}[ht]
    \centerfloat{
        \includegraphics[width=1.0\linewidth]{sec1_transformer.png}
    }
    \caption[Схема архитектуры модели трансформера]{Схема архитектуры модели трансформера}\label{fig:sec1_transformer}
\end{figure}

Нейросетевые методы особенно успешно применяются к распознаванию печатных документов и современных часто используемых иероглифов, где доступны большие размеченные корпуса данных. Базы данных, такие как \cite{xu2019casia} для китайского текста, позволяют обучать глубокие сети, достигая точности, сопоставимой с человеческой, особенно в условиях стандартного сканирования и минимального уровня шума.

% Приемущества и недостатки
Тем не менее, у нейросетевых методов есть ряд существенных ограничений, которые непосредственно связаны с задачами обработки исторических и редких иероглифов. Во-первых, они требуют больших размеченных корпусов для эффективного обучения; без достаточного количества примеров модель просто не может выучить представления для каждого класса. Во-вторых, эти методы плохо работают с редкими, устаревшими или ранее не встречавшимися символами, поскольку такие классы либо отсутствуют в обучающем наборе, либо представлены слишком слабо для адекватного обучения. В-третьих, современные глубокие модели требуют высокой вычислительной стоимости как при обучении, так и при выводе, что затрудняет их применение в ресурсно-ограниченных средах. И, наконец, архитектуры глубоких сетей часто характеризуются низкой интерпретируемостью, поскольку внутренние представления и принятие решений сложно связать с осмысленными компонентами формы символа.

Таким образом, несмотря на высокую точность, нейросетевые методы ориентированы прежде всего на задачу расшифровки текста и слабо приспособлены к задачам поиска редких иероглифов в условиях отсутствия обучающих данных.

Для преодоления ограничений каждого из указанных направлений были предложены гибридные системы, сочетающие преимущества разработанных традиционных и статистических признаков и глубокого обучения \cite{wang2014mqdf, liu2016offline, li2016handwritten}. Такие подходы позволяют повысить устойчивость распознавания и снизить требования к объёму обучающих данных, однако и они демонстрируют низкую эффективность в условиях крайне ограниченного числа примеров.


\section{Методы, основанные на принципе поиска}\label{sec:ch1/sec2}
Методы, применяемые при принципе поиска, представляют собой альтернативное и в ряде прикладных сценариев принципиально важное направление в области анализа иероглифических текстов. В литературе такие подходы известны как однократное обучение (One-shot Learning)\cite{vinyals2016matching, snell2017prototypical, he2020memory}. В отличие от методов расшифровки, ориентированных на восстановление точного символического представления, поисковые подходы нацелены прежде всего на выявление, сопоставление и группировку изображений по степени их визуального или структурного сходства. Такие методы особенно востребованы в задачах анализа исторических документов, архивных коллекций и малоизученных письменных источников, где полная расшифровка текста затруднена или невозможна из-за отсутствия словарей, редкости символов или сильной деградации изображений.

Ключевой особенностью поисковых методов является их относительная независимость от полного набора классов иероглифов и строгой лингвистической интерпретации. Вместо этого они оперируют понятием мерой близости, что позволяет решать задачи поиска в больших массивах изображений, обнаружения повторяющихся символов, сопоставления вариантов написания и поддержки экспертной расшифровки.

В рамках данной группы методов можно выделить три основных класса подходов. Первый класс составляют методы шаблонного сопоставления, в которых сравнение иероглифов осуществляется напрямую на уровне изображений или их структурных представлений, таких как контуры, скелеты или графы штрихов. Второй класс включает метрические методы в признаковом пространстве, где иероглифы отображаются в векторное пространство признаков, а задача поиска формулируется как вычисление расстояний или мер сходства между представлениями. Третий класс представлен методами, основанными на предобученных представлениях и инженерии подсказок (prompt engineering), которые заимствуют идеи из современных моделей глубокого обучения и больших языковых и мультимодальных моделей.

\subsection{Методы шаблонного сопоставления}
Методы шаблонного сопоставления базируются на прямом сравнении изображений символов или их представлений в виде наборов базовых элементов, без явного этапа классификации. В отличие от подходов, основанных на обучении моделей на размеченных данных, эти алгоритмы сравнивают входной образец с заранее заданными эталонами, оценивая степень согласованности форм. Такая стратегия особенно естественна, когда требуется определить, насколько визуально схожи два изображения, и позволяет напрямую измерять близость между ними.

Одним из классических способов прямого сравнения являются корреляционные меры, основанные на вычислении нормированной корреляции между пиксельными значениями входного изображения и шаблона. Нормированная кросс-корреляция (Normalized Cross-Correlation, NCC) и её вариации широко использовались в ранних системах обработки изображений для сопоставления объектов на различных позициях и масштабах, поскольку корреляция позволяет учесть как структурные, так и интенсивностные совпадения между паттернами. Такие меры традиционно применялись в задачах шаблонного распознавания символов, где все символы были приведены к единому масштабу и ориентации \cite{8354319, lanjewar2021template}.

Другой важной группой методов является сравнение контуров, где форма символа представляется только его границей. Такие подходы используют анализ границы (contour) для извлечения ключевых структурных точек и описания формы символа, что облегчает последующее сопоставление. В ранних работах по извлечению штрихов китайских символов показано, что информация о контуре, доминантных точках и угловых точках может служить основой для описания структуры иероглифа \cite{lee1998chinese}. В задачах обработки сложных рукописных образцов сопоставление верхнего и нижнего контура с помощью алгоритмов наподобие DTW позволяет определять разбиение слитных символов и выявлять характерные точки для последующего сравнения форм \cite{xu2010touching}. Кроме того, различная работа, основанная на преобразованиях контура, демонстрирует, что контурные признаки могут эффективно описывать форму иероглифа для задач сравнения и поиска \cite{tao1999feature}.

Наконец, в рамках методов сопоставления скелетов значительное внимание уделяется представлению символа через его топологическую «костную» структуру, которая сохраняет важнейшие особенности штрихов и их взаимосвязей. В частности, в исследовании по распознаванию китайской каллиграфической графемы была предложена алгоритмическая схема скелетизации, способная извлекать минимально деформированные скелетные структуры, на основании которых производится распознавание и сравнение форм \cite{yu2008skeleton}. Аналогично, в работах по деформации и сравнительному анализу различных стилей китайских иероглифов строятся атрибутные графы на основе выделенных узлов и ребер, а затем применяется алгоритмическое сопоставление графов для установления соответствий между различными формами \cite{liu2015morphing}.

Ключевым преимуществом методов шаблонного сопоставления является их простота: алгоритмы прямого сравнения легко реализуются и интерпретируются, а также не требуют обучения на размеченных данных — достаточно иметь набор эталонных шаблонов. Это делает такие методы привлекательными в условиях, когда отсутствуют крупные размеченные датасеты или когда задача состоит исключительно в поиске визуального совпадения форм.

Тем не менее у этих подходов имеются существенные недостатки. Во-первых, они характеризуются низкой устойчивостью к деформациям, шумам и вариативности почерка: прямое сопоставление пикселей или контуров часто даёт большие ошибки в случаях, когда символ частично повреждён, искажен или написан под углом. Во-вторых, методы шаблонного сопоставления могут иметь высокую вычислительную сложность при сравнении с большим числом эталонных шаблонов, особенно если сравнения проводятся во всевозможных позициях, масштабах и ориентациях. Это ограничивает их практическую применимость для задач с большими наборами символов и разнообразными источниками изображений.

\subsection{Метрические методы в признаковом пространстве}
Метрические методы представляют собой класс подходов, в которых каждый иероглиф отображается как вектор в некотором признаковом пространстве, полученном с помощью нейросетевого или другого алгоритма извлечения признаков. В этом пространстве вычисляется расстояние между векторами, и для задачи поиска ближайших объектов используется мера расстояния (например, евклидово или косинусное расстояние). Такой подход позволяет формировать пространство, в котором объекты одной категории близки друг к другу, а объекты разных категорий — далеко друг от друга, что естественно формулируется как задача поиска ближайших соседей. Этот принцип лежит в основе методов метрик-обучения (metric learning), которые учат такое пространство признаков, где сравнение новых образцов со всеми представленными эталонами осуществляется напрямую через расстояние между векторами.

Одной из ключевых архитектур в этой области являются сиамские сети (Siamese Networks), которые состоят из двух идентичных подсетей с общими весами, обучаемых на парах изображений — схожих и различающихся по классу. Сеть учится предсказывать мера сходства между двумя образами, что позволяет использовать полученное пространство признаков для поиска похожих символов по небольшому числу примеров. На рисунке \cref{fig:sec1_siamese_networks_method} приведена схема работы сиамских-сетей при сравнении иероглифических изображений.

\begin{figure}[ht]
    \centerfloat{
        \includegraphics[width=0.9\linewidth]{sec1_siamese_networks_method.jpg}
    }
    \caption[Схема сиамских-сетей для сравнения иероглифов]{Схема сиамских-сетей для поиска иероглифов. Обучение сетей происходится через максимизацию сходства при паре изображений из одного класса.}\label{fig:sec1_siamese_networks_method}
\end{figure}


Сиамская архитектура представляет собой отображение $f_{\theta}: \mathcal{X} \to \mathbb{R}^d$, где $\theta$ — общие параметры двух идентичных подсетей. На вход подается пара изображений $(x_i, x_j)$. Обучение направлено на минимизацию функции контрастного потерь (Contrastive Loss):
\[
    L_{siamese}(x_i, x_j, y_{ij}) = (1 - y_{ij}) * \frac{1}{2} * D_{\theta}^2 + y_{ij} * \frac{1}{2} *\max(0, m - D_{\theta})^2,
\]
где $D_{\theta} = \|f_{\theta}(x_i) - f_{\theta}(x_j)\|_2$ — евклидово расстояние между эмбеддингами; $y_{ij} \in \{0, 1\}$ — индикатор сходства ($0$ для объектов одного класса, $1$ для разных); $m > 0$ — гиперпараметр (margin), задающий минимально допустимое расстояние между несамоподобными объектами. Такие сети широко используются в задачах однократного или малократного обучения, где цель состоит в том, чтобы распознавать новые категории с минимальным количеством примеров, часто всего с одним образцом на класс. Схема работы сиамских сетей при практического применения в поиске и однократном распознавании показана на рисунке \cref{fig:sec1_siamese_networks_one_shot}. В частности, аналогичный подход используется в недавно предложенной работе по однократное распознаванию древних символов с помощью сиамской сети, где модель обучается отличать пары изображений на основе их эмбеддингов-представления и затем применяет размерность расстояния к новому образцу для классификации \cite{liu2022one}.

\begin{figure}[ht]
    \centerfloat{
        \includegraphics[width=1.0\linewidth]{sec1_siamese_networks_one_shot.jpg}
    }
    \caption[]{Схема работы сиамских-сетей при поиске иероглифов. Для однократного обучения или поиского запроса сиамская нейронная сеть преобразует опорные (support sample) и тестовый (test sample) иероглифы в общее признаковое пространство, вычисляет их попарное сходство и определяет результат распознавания по максимальному значению сходства.}\label{fig:sec1_siamese_networks_one_shot}
\end{figure}

Триплетные сети расширяют идею сиамских сетей, используя одновременно три входных экземпляра: якорь $x^a$, положительный пример $x^p$ (того же класса, что и $x^a$) и отрицательный пример $x^n$ (другого класса). Целью обучения является выполнение условия:
$$
    \|f_{\theta}(x^a) - f_{\theta}(x^p)\|_2^2 + \alpha < \|f_{\theta}(x^a) - f_{\theta}(x^n)\|_2^2.
$$
Для оптимизации параметров $\theta$ используется функция потерь триплета (Triplet Loss), основная идея которой представлена на рисунке \cref{fig:sec1_triplet}:
$$
    L_{triplet}(x^a, x^p, x^n) = \sum_{i}^N \max \left( 0, \|f_{\theta}(x_i^a) - f_{\theta}(x_i^p)\|_2^2 - \|f_{\theta}(x_i^a) - f_{\theta}(x_i^n)\|_2^2 + \alpha \right),
$$
где $\alpha$ — маржа, определяющая требуемую степень разделения между внутриклассовыми и межклассовыми расстояниями. С помощью функции потерь триплета модель обучается так, чтобы расстояние между якорем и положительным примером было меньше расстояния между якорем и отрицательным образцом как минимум на некоторую маржу, что формирует более чёткую кластеризацию в пространстве эмбеддингов. Такой подход доказал свою эффективность в задачах извлечения семантически значимых признаков и широко применяется в медицинских и визуальных задачах распознавания.

\begin{figure}[ht]
    \centerfloat{
        \includegraphics[width=1.0\linewidth]{sec1_triplet_loss.png}
    }
    \caption[]{Функция потерь триплета минимизирует расстояние между якорным и положительным образцами одного класса и максимизирует расстояние между якорным и отрицательным образцом другого класса.}\label{fig:sec1_triplet}
\end{figure}

Преимущество метрических методов заключается в возможности работать с открытым словарём и в формальной постановке задачи поиска: поскольку сравнение новых образцов с известными классами осуществляется исключительно через расстояние в признаковом пространстве, после обучения модель может справляться с категориями, которые не были представлены во время тренировки. Это делает их особенно привлекательными для задач распознавания редких иероглифов, где практически невозможно собрать большие размеченные наборы для каждого класса.

Однако у таких методов есть свои ограничения. Во-первых, они требуют предварительного обучения эмбеддинговой модели на репрезентативном наборе данных, чтобы обеспечить качественное пространство признаков. Без такой подготовки метрики могут быть плохо сформированы, что приводит к ошибкам при сравнении. Во-вторых, пространство эмбеддингов зачастую неинтерпретируемо: хотя близость в пространстве коррелирует с визуальным или семантическим сходством, отдельные измерения вектора трудно связать с понятными человеческому анализу характеристиками формы, что затрудняет объяснение результатов и анализ ошибок.

\subsection{Предобученные представления и методы инженерии подсказок (Prompt Engineering)}
В последние годы развитие больших предварительно обученных моделей (large pretrained models), включая языковые модели (LLMs) и визуально-языковые модели (Vision-Language Models, VLM/MLLM), привело к появлению нового класса подходов к задачам, связанным с извлечением и интерпретацией текстовой информации из изображений. Пример таких моделей и его основые принципы работы при распознавании приведена на рисунке \cref{fig:sec1_vlm_ocr}. Эти модели обучаются на огромных корпусах текстов и/или изображений, что позволяет им усваивать богатые семантические и визуальные представления, пригодные для разнообразных последующих задач без необходимости обучения на больших специализированных данных. Такая предварительная подготовка существенно расширяет возможности моделей в условиях недостаточности размеченных данных и делает возможным применение метода инженерии подсказок (prompt engineering) для адаптации к новым задачам.

\begin{figure}[ht]
    \centerfloat{
        \includegraphics[width=1.0\linewidth]{sec1_vlm_ocr.jpg}
    }
    \caption[]{Пример визуально-языковой модели HunyuanOCR \cite{hunyuanvisionteam2025hunyuanocrtechnicalreport}, предназначенной для решения широкого спектра задач оптического распознавания китайского текста, включая: обнаружение и локализацию текста (text spotting), структурный разбор (parsing), извлечение информации, визуальный вопросно-ответный анализ (visual question answering) и перевод текста на изображениях.}\label{fig:sec1_vlm_ocr}
\end{figure}

В контексте распознавание текстов и связанных визуально-текстовых задач использование языковых и визуально-языковых моделей характеризуется следующими практиками. Во-первых, контекстуальные подсказки (prompts) или инструкции на естественном языке могут быть добавлены к входным данным, чтобы указать модели, каким образом извлекать текст или интерпретировать визуальное содержимое изображения. Во-вторых, так называемое онлайновое обучение (in-context learning) позволяет моделям генерировать ответы на новые примеры на основе нескольких примеров (few-shot) без изменения параметров модели. Это особенно актуально для задач, где размеченные обучающие наборы ограничены. В литературе по инженерии подсказок обсуждаются как hard prompts (текстовые шаблоны), так и soft prompts (континуальные векторы в пространстве эмбеддингов), используемые для адаптации предобученных визуально-языковых моделей к различным задачам, включая классификацию, описание изображений и сопоставление изображений с текстом \cite{gu2023systematic}.

Одним из основных способов применения VLM/MLLM к задачам распознавания текстов является встраивание текстового контекста и подсказок в запрос, что позволяет моделям не только извлекать текст из изображения, но и генерировать текстовые гипотезы с учётом семантики предложения и внешнего контекста. Подходы few-shot prompting, где к запросу добавляются несколько примеров с ответами, помогают модели адаптироваться к формату задачи и сокращать зависимость от структурированных размеченных данных. Именно такие подходы уже активно исследуются в задачах обработки естественного языка (например, в китайской текстовой классификации), где метод инженерии подсказок позволяет моделям предобученными представлениями эффективно работать в ресурсно-ограниченных условиях \cite{song2022investigating, liu2023hidden}.

Одним из ключевых преимуществ подобных подходов является минимизация необходимости ручной разметки данных: большая часть знаний инкапсулирована в предобученной модели, и задача сводится к правильной формулировке подсказок и выбору контекста для модели. Это обеспечивает гибкость применения, позволяя легко адаптировать модель под разные задачи извлечения текста или анализа структуры, в том числе для сложных или редких сценариев.

Однако важно отметить ряд существенных ограничений. Во-первых, такие методы зачастую решают задачу непосредственно не как распознавание текстов, а как мультимодальное понимание сцены, что может быть непрямым решением задачи чистого распознавания текстов, особенно на уровне символов. Во-вторых, модели сильно зависят от внешних языковых знаний и контекста, что может приводить к ошибкам распознавания в условиях редких или несемантических символов (например, древние или редкие иероглифы). В-третьих, полученные эмбеддингов-представления и выходы моделей часто не имеют строгой метрической интерпретации сходства форм, что затрудняет формальное сравнение образов в строгом математическом смысле.

\section{Выводы к главе \ref{ch:ch1}}
Проведённый систематический обзор выявил принципиальные ограничения существующих методов при обработке исторических рукописных документов.

Методы расшифровки, несмотря на высокую точность на стандартизированных датасетах, критически зависят от обширных размеченных корпусов и неэффективны при работе с редкими или ранее не встречавшимися иероглифами. Традиционные дескрипторы обладают низкой устойчивостью к деградациям, а нейросетевые архитектуры не способны обобщаться на классы, отсутствующие в обучающей выборке.

Методы поиска, ориентированные на выявление визуального сходства, потенциально работают с открытым словарём, однако методы шаблонного сопоставления чувствительны к деформациям, метрические методы требуют предварительного обучения на репрезентативных данных, а подходы на основе визуально-языковых моделей зависят от внешнего контекста и решают задачу косвенно.

Таким образом, существующие подходы демонстрируют фундаментальное противоречие: методы расшифровки обеспечивают точное представление, но неприменимы к редким классам, а поисковые методы недостаточно устойчивы или требуют обширной разметки. Это критично для древних китайских рукописей с ограниченным числом размеченных примеров, высокой вариативностью почерка и архаическими формами.

Выявленные ограничения обосновывают необходимость разработки метода, способного извлекать устойчивые дискриминативные признаки в условиях ограниченных данных с сохранением способности обобщения на редкие классы символов.
\FloatBarrier
